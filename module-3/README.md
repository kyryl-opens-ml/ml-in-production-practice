# Module 3

![alt text](./../docs/experiments.jpg)

# Practice

[Practice task](./PRACTICE.md)

***

# Reference implementation

***

## Project stucture

- [Python project](https://github.com/navdeep-G/samplemod.git)
- [ML project](https://github.com/ashleve/lightning-hydra-template.git)
- [Advanced features](https://github.com/Lightning-AI/lightning)

## Configuration

[hydra](https://hydra.cc/docs/intro/)

## Experiments management

https://neptune.ai/blog/best-ml-experiment-tracking-tools

## Model card

- [Model Cards for Model Reporting](https://arxiv.org/abs/1810.03993)
- [A collection of machine learning model cards and datasheets.](https://github.com/ivylee/model-cards-and-datasheets)
- [GPT-4o](https://openai.com/index/hello-gpt-4o/)
- [GPT-4 System Card](https://cdn.openai.com/papers/gpt-4-system-card.pdf)

## Classic example Example ML model with testing: BERT-based training

[nlp-sample](./nlp-sample)


## Eval:

- https://github.com/explodinggradients/ragas
- https://github.com/NVIDIA/NeMo-Guardrails
- https://github.com/guardrail-ml/guardrail
- https://github.com/promptfoo/promptfoo
- https://github.com/confident-ai/deepeval



```
pip install nemoguardrails
pip install openai
export OPENAI_API_KEY=**********
```



# Distributed training 

- https://www.anyscale.com/blog/what-is-distributed-training
- https://www.anyscale.com/blog/training-175b-parameter-language-models-at-1000-gpu-scale-with-alpa-and-ray
- https://huggingface.co/docs/transformers/perf_train_gpu_many
- https://github.com/microsoft/DeepSpeed


# Hyperparameter search & AutoML

- https://github.com/microsoft/nni
- https://github.com/autogluon/autogluon
